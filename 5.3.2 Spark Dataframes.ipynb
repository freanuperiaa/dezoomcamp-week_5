{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc631f32-ef88-40a8-8917-ff7404177ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53a6de7-9f41-4de4-8a71-d08d8e150b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/02 16:55:29 WARN Utils: Your hostname, coy-pc resolves to a loopback address: 127.0.1.1; using 172.19.138.153 instead (on interface eth0)\n",
      "24/03/02 16:55:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/02 16:55:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .appName('FirstLook') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac5f9e2-d696-4769-b62e-f6ccd17611df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e521357-d8e5-41bc-a1dd-13abc8d64d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a329b42b-b556-4c69-9bcf-42d668ed7adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving data from Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "254ba7d2-74bd-47bd-84a7-de4f7141c96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DoLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-01 11:42:02|2021-01-01 12:00:51|          85|          11|\n",
      "|2021-01-01 03:31:07|2021-01-01 03:38:10|         129|          82|\n",
      "|2021-01-01 17:59:21|2021-01-01 18:17:29|          14|          26|\n",
      "|2021-01-01 21:18:30|2021-01-01 21:27:55|          39|          39|\n",
      "|2021-01-01 21:58:38|2021-01-01 22:05:07|          20|          20|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DoLocationID') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "    .show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7386a20-4c4c-4fee-bf59-ba86ea0c84b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "451a2898-bd93-4c95-ab73-9b528289caa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+------------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|pickup_date|dropoff_date|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+------------+\n",
      "|           HV0003|              B02765|2021-01-01 11:42:02|2021-01-01 12:00:51|          85|          11|   null| 2021-01-01|  2021-01-01|\n",
      "|           HV0003|              B02869|2021-01-01 03:31:07|2021-01-01 03:38:10|         129|          82|   null| 2021-01-01|  2021-01-01|\n",
      "|           HV0003|              B02872|2021-01-01 17:59:21|2021-01-01 18:17:29|          14|          26|   null| 2021-01-01|  2021-01-01|\n",
      "|           HV0003|              B02869|2021-01-01 21:18:30|2021-01-01 21:27:55|          39|          39|   null| 2021-01-01|  2021-01-01|\n",
      "|           HV0003|              B02879|2021-01-01 21:58:38|2021-01-01 22:05:07|          20|          20|   null| 2021-01-01|  2021-01-01|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the DataFrame.withColumn() function adds new column if first param is nonexistent. else, it replaces the already existing column\n",
    "\n",
    "df\\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .show(n=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32c49709-fe71-4c4f-af39-ee777ea0723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|pickup_date|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+\n",
      "|           HV0003|              B02765|2021-01-01 11:42:02|2021-01-01 12:00:51|          85|          11|   null| 2021-01-01|\n",
      "|           HV0003|              B02869|2021-01-01 03:31:07|2021-01-01 03:38:10|         129|          82|   null| 2021-01-01|\n",
      "|           HV0003|              B02872|2021-01-01 17:59:21|2021-01-01 18:17:29|          14|          26|   null| 2021-01-01|\n",
      "|           HV0003|              B02869|2021-01-01 21:18:30|2021-01-01 21:27:55|          39|          39|   null| 2021-01-01|\n",
      "|           HV0003|              B02879|2021-01-01 21:58:38|2021-01-01 22:05:07|          20|          20|   null| 2021-01-01|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .select('*') \\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003') \\\n",
    "    .show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2299fcb-3111-4b76-896d-617213064953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making use of Pyspark User-Defined Functions (UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a7ad637-bf4f-4af4-afc6-19f0e83ccc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2059fe43-99bc-429c-9d51-feab1b79b466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s/b44'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crazy_stuff('B02884')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "238f5470-c017-4276-a210-de4794b51b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "664dd2fd-03f5-4728-bc73-c9716ef44201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+------------+------------+\n",
      "|base_id|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "|  s/acd| 2021-01-01|  2021-01-01|          85|          11|\n",
      "|  e/b35| 2021-01-01|  2021-01-01|         129|          82|\n",
      "|  e/b38| 2021-01-01|  2021-01-01|          14|          26|\n",
      "|  e/b35| 2021-01-01|  2021-01-01|          39|          39|\n",
      "|  e/b3f| 2021-01-01|  2021-01-01|          20|          20|\n",
      "|  s/b3d| 2021-01-02|  2021-01-02|         236|         220|\n",
      "|  s/acd| 2021-01-01|  2021-01-01|          31|          32|\n",
      "|  a/b37| 2021-01-01|  2021-01-01|          36|          36|\n",
      "|  e/b47| 2021-01-01|  2021-01-01|         260|           7|\n",
      "|  e/9ce| 2021-01-02|  2021-01-02|          92|         171|\n",
      "|  e/acc| 2021-01-02|  2021-01-02|         158|         125|\n",
      "|  e/9ce| 2021-01-02|  2021-01-02|         114|          14|\n",
      "|  e/b35| 2021-01-01|  2021-01-01|          32|          42|\n",
      "|  e/9ce| 2021-01-02|  2021-01-02|         100|         163|\n",
      "|  s/acd| 2021-01-01|  2021-01-01|          61|          37|\n",
      "|  s/b13| 2021-01-01|  2021-01-01|          63|          42|\n",
      "|  s/acd| 2021-01-02|  2021-01-02|          48|         258|\n",
      "|  e/b38| 2021-01-01|  2021-01-01|         260|         173|\n",
      "|  e/acc| 2021-01-01|  2021-01-01|         225|         265|\n",
      "|  e/9ce| 2021-01-01|  2021-01-01|         142|         137|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "    .select('base_id', 'pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f2a643-e098-4a45-a742-0bdbdb513f31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15907269-912c-458d-944e-8bc3dbe403b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba1b031-711b-4b3e-8105-3278ee541c44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
